{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "dq0G6u0MWl8q"
      },
      "outputs": [],
      "source": [
        "\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from datetime import datetime\n",
        "\n",
        "# Load the dataset\n",
        "data = pd.read_csv(\"/content/breast_cancer_survival.csv\") # Replace \"your_dataset.csv\" with the path to your dataset file\n",
        "\n",
        "# Dropping rows with missing values\n",
        "data.dropna(inplace=True)\n",
        "\n",
        "# Separate features and target variable\n",
        "X = data.drop(columns=[\"Patient_Status\"])\n",
        "y = data[\"Patient_Status\"]\n",
        "\n",
        "# Encoding categorical variables\n",
        "encoder = LabelEncoder()\n",
        "X_encoded = X.copy()\n",
        "for col in X.columns:\n",
        "    if X[col].dtype == 'object':\n",
        "            X_encoded[col] = encoder.fit_transform(X[col])\n",
        "\n",
        "# One-hot encoding categorical variables\n",
        "categorical_cols = ['Tumour_Stage', 'Histology', 'ER status', 'PR status', 'HER2 status', 'Surgery_type']\n",
        "X_encoded = pd.get_dummies(X_encoded, columns=categorical_cols)\n",
        "\n",
        "            # Convert date variables to numerical representation\n",
        "date_columns = ['Date_of_Surgery', 'Date_of_Last_Visit']\n",
        "for col in date_columns:\n",
        "        X_encoded[col] = pd.to_datetime(X_encoded[col], errors='coerce')\n",
        "        X_encoded[col] = (X_encoded[col] - datetime(1970, 1, 1)).dt.total_seconds()\n",
        "\n",
        "                    # Splitting the dataset into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_encoded, y, test_size=0.2, random_state=42)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from datetime import datetime\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "# Load the dataset\n",
        "data = pd.read_csv(\"/content/breast_cancer_survival.csv\") # Replace \"your_dataset.csv\" with the path to your dataset file\n",
        "\n",
        "# Dropping rows with missing values\n",
        "data.dropna(inplace=True)\n",
        "\n",
        "# Separate features and target variable\n",
        "X = data.drop(columns=[\"Patient_Status\"])\n",
        "y = data[\"Patient_Status\"]\n",
        "\n",
        "# Encoding categorical variables\n",
        "encoder = LabelEncoder()\n",
        "X_encoded = X.copy()\n",
        "for col in X.columns:\n",
        "    if X[col].dtype == 'object':\n",
        "        X_encoded[col] = encoder.fit_transform(X[col])\n",
        "\n",
        "# One-hot encoding categorical variables\n",
        "categorical_cols = ['Tumour_Stage', 'Histology', 'ER status', 'PR status', 'HER2 status', 'Surgery_type']\n",
        "X_encoded = pd.get_dummies(X_encoded, columns=categorical_cols)\n",
        "\n",
        "# Convert date variables to numerical representation\n",
        "date_columns = ['Date_of_Surgery', 'Date_of_Last_Visit']\n",
        "for col in date_columns:\n",
        "    X_encoded[col] = pd.to_datetime(X_encoded[col], errors='coerce')\n",
        "    X_encoded[col] = (X_encoded[col] - datetime(1970, 1, 1)).dt.total_seconds()\n",
        "\n",
        "# Splitting the dataset into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_encoded, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initializing Gradient Boosting classifier\n",
        "gb_classifier = GradientBoostingClassifier(n_estimators=100, random_state=42)\n",
        "\n",
        "# Training the Gradient Boosting model\n",
        "gb_classifier.fit(X_train, y_train)\n",
        "\n",
        "# Predicting on the test set using Gradient Boosting\n",
        "y_pred_gb = gb_classifier.predict(X_test)\n",
        "\n",
        "# Evaluating the Gradient Boosting model\n",
        "accuracy_gb = accuracy_score(y_test, y_pred_gb)\n",
        "print(\"Gradient Boosting Accuracy:\", accuracy_gb)\n",
        "print(\"\\nGradient Boosting Classification Report:\\n\", classification_report(y_test, y_pred_gb))\n",
        "\n",
        "# Encoding target variable y\n",
        "label_encoder = LabelEncoder()\n",
        "y_train_encoded = label_encoder.fit_transform(y_train)\n",
        "y_test_encoded = label_encoder.transform(y_test)\n",
        "\n",
        "# Initializing XGBoost classifier\n",
        "xgb_classifier = XGBClassifier(n_estimators=100, random_state=42)\n",
        "\n",
        "# Training the XGBoost model\n",
        "xgb_classifier.fit(X_train, y_train_encoded)\n",
        "\n",
        "# Predicting on the test set using XGBoost\n",
        "y_pred_xgb = xgb_classifier.predict(X_test)\n",
        "\n",
        "# Evaluating the XGBoost model\n",
        "accuracy_xgb = accuracy_score(y_test_encoded, y_pred_xgb)\n",
        "print(\"\\nXGBoost Accuracy:\", accuracy_xgb)\n",
        "print(\"\\nXGBoost Classification Report:\\n\", classification_report(y_test_encoded, y_pred_xgb))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UGE8aS-HWxEp",
        "outputId": "a77dcb59-af83-47cd-def2-4a6dc5f4047c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gradient Boosting Accuracy: 0.78125\n",
            "\n",
            "Gradient Boosting Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "       Alive       0.80      0.96      0.88        51\n",
            "        Dead       0.33      0.08      0.12        13\n",
            "\n",
            "    accuracy                           0.78        64\n",
            "   macro avg       0.57      0.52      0.50        64\n",
            "weighted avg       0.71      0.78      0.72        64\n",
            "\n",
            "\n",
            "XGBoost Accuracy: 0.765625\n",
            "\n",
            "XGBoost Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.81      0.92      0.86        51\n",
            "           1       0.33      0.15      0.21        13\n",
            "\n",
            "    accuracy                           0.77        64\n",
            "   macro avg       0.57      0.54      0.54        64\n",
            "weighted avg       0.71      0.77      0.73        64\n",
            "\n"
          ]
        }
      ]
    }
  ]
}